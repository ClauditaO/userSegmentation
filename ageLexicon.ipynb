{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25115292\t31\n"
     ]
    }
   ],
   "source": [
    "intercept = 23.2188604687\n",
    "lexicon = dict()\n",
    "no_weights_lexicon = dict()\n",
    "\n",
    "dirname = '/home/clau/Documents/journal_five_countries/'\n",
    "\n",
    "for file1 in os.listdir(dirname+'/journos_tweets_uk/'):\n",
    "    lexicon_file = codecs.open('/home/clau/userSegmentationPaper/resources/ageLexicon.txt')\n",
    "    for line in lexicon_file:\n",
    "        word_weight = line.split('\\t')\n",
    "        lexicon[word_weight[0]] = float(word_weight[1].strip())\n",
    "        no_weights_lexicon[word_weight[0]] = 0\n",
    "    lexicon_file.close()\n",
    "    #print(file)\n",
    "    this_user_lexicon = dict()\n",
    "    this_user_lexicon = no_weights_lexicon\n",
    "    lexicon_usage = 0\n",
    "    this_user_tweets = codecs.open(dirname+'/journos_tweets_uk/'+file1, 'r', encoding='utf-8')\n",
    "    tweets_text = ''\n",
    "    for line in this_user_tweets:\n",
    "        pieces = line.split('\\t')\n",
    "        tweets_text = tweets_text+' '+pieces[0].replace('\\n\\n','\\n')\n",
    "    users_tokens = tweets_text.split(' ')\n",
    "    total_words_used = len(users_tokens)\n",
    "    #print(total_words_used)\n",
    "    for token in users_tokens:\n",
    "        if token in this_user_lexicon:\n",
    "            this_user_lexicon[token] += 1\n",
    "    for k,v in this_user_lexicon.items():\n",
    "        if v > 0:\n",
    "            lexicon_usage = lexicon_usage + ((v/total_words_used)*lexicon[k])\n",
    "    #print(lexicon_usage)\n",
    "    age = lexicon_usage + intercept\n",
    "    print(file1.replace('.txt','')+'\\t'+str(round(age)))\n",
    "    this_user_tweets.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       male       0.18      0.01      0.02       159\n",
      "     female       0.71      0.98      0.82       388\n",
      "\n",
      "avg / total       0.55      0.70      0.59       547\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
